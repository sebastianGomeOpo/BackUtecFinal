# ðŸ“Š LangSmith Integration Guide

## Â¿QuÃ© es LangSmith?

LangSmith es una plataforma de observabilidad para aplicaciones LLM que te permite:

- **Rastrear (Trace)** cada llamada al LLM, herramientas y procesos intermedios
- **Debuggear (Debug)** problemas visualizando el flujo completo
- **Evaluar (Evaluate)** la calidad de respuestas automÃ¡ticamente
- **Monitorear (Monitor)** uso de API, costos y latencias
- **Optimizar (Optimize)** prompts sin cambiar cÃ³digo

---

## ðŸš€ Inicio RÃ¡pido

### 1. Registrarse en LangSmith
1. Visita https://smith.langchain.com
2. Haz clic en "Sign Up"
3. Completa el registro (puedes usar GitHub)
4. Confirma tu email

### 2. Obtener API Key
1. En el dashboard de LangSmith, ve a **Settings** (Ã­cono de engranaje)
2. Haz clic en **API Keys**
3. Crea una nueva key o copia la existente
4. Copia el valor completo

### 3. Configurar Proyecto

#### OpciÃ³n A: Archivo .env.local (Recomendado)
```env
# .env.local
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_pt_your-api-key-here
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_PROJECT=utec-sales-agent
```

#### OpciÃ³n B: Variables de Sistema
```bash
# macOS/Linux
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY=lsv2_pt_your-api-key-here
export LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
export LANGCHAIN_PROJECT=utec-sales-agent

# Windows PowerShell
$env:LANGCHAIN_TRACING_V2="true"
$env:LANGCHAIN_API_KEY="lsv2_pt_your-api-key-here"
$env:LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
$env:LANGCHAIN_PROJECT="utec-sales-agent"
```

### 4. Verificar que Funciona

```bash
# Reinicia la API
python main.py

# En otra terminal, haz una solicitud
curl -X POST http://localhost:8000/api/agent/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hola, necesito una mesa"}'

# Espera unos segundos y ve a https://smith.langchain.com
# DeberÃ­as ver trazas en el proyecto "utec-sales-agent"
```

---

## ðŸ“– CÃ³mo Funciona en el Proyecto

### Trazas AutomÃ¡ticas

Cuando `LANGCHAIN_TRACING_V2=true`, automÃ¡ticamente se rastrean:

```
Chat Request
â”œâ”€ Message: "Quiero una mesa"
â”œâ”€ Sales Agent Node
â”‚  â”œâ”€ OpenAI Call (gpt-4o-mini)
â”‚  â”‚  â””â”€ Total tokens: 342
â”‚  â”œâ”€ Product Search (ChromaDB)
â”‚  â”‚  â””â”€ Resultados: 5 productos
â”‚  â””â”€ Response
â”œâ”€ Supervisor Node
â”‚  â””â”€ Routing decision
â””â”€ Response to User
```

Cada uno de estos pasos es **rastreable** en LangSmith.

### Ejemplo: Rastrear un Chat

```python
# En src/presentation/routes/agent.py
# Las trazas se capturan automÃ¡ticamente

@router.post("/chat")
async def chat(request: ChatRequest):
    # LangSmith automÃ¡ticamente registra:
    # 1. Entrada del usuario
    # 2. Llamadas a LLM
    # 3. BÃºsquedas de productos
    # 4. Decisiones del supervisor
    # 5. Salida final

    response = await graph.ainvoke(...)
    return response
```

---

## ðŸ” Usando LangSmith Dashboard

### Vista Principal

1. **Projects** - Todos tus proyectos (e.g., "utec-sales-agent")
2. **Runs** - Todas las ejecuciones/trazas
3. **Tests** - Crear datasets de prueba
4. **Datasets** - Datos para evaluaciÃ³n

### Inspeccionar una Traza

```
Haz clic en cualquier "Run" en la lista
â†“
Se abre la traza con:
  - Ãrbol de llamadas (quÃ© llamÃ³ a quÃ©)
  - Tokens usados
  - Latencia (tiempo de respuesta)
  - Inputs y outputs
  - Errores (si hay)
```

### Ejemplo: Debug de Problema

**Problema:** "El agente no encuentra productos"

**SoluciÃ³n con LangSmith:**
1. Ve a tu proyecto
2. Filtra por Ãºltima ejecuciÃ³n
3. Abre la traza
4. Busca el nodo "search_products"
5. Inspecciona la query que se enviÃ³ a ChromaDB
6. Mira los resultados retornados
7. Identifica si el problema es la query o la bÃºsqueda

---

## ðŸ“Š EvaluaciÃ³n AutomÃ¡tica

### Crear Dataset de Prueba

```python
# En LangSmith Dashboard:
# 1. Ve a "Datasets"
# 2. Haz clic en "Create Dataset"
# 3. Agrega ejemplos:
#    Input: "Quiero una mesa grande"
#    Expected Output: [ID del producto de mesa]
```

### Ejecutar EvaluaciÃ³n

```bash
# OpciÃ³n 1: Desde LangSmith UI
# - Ve a tu dataset
# - Clic en "Evaluate"
# - Selecciona evaluador (e.g., "Exact Match")

# OpciÃ³n 2: Desde cÃ³digo (avanzado)
from langsmith import evaluate
from src.main import graph

results = evaluate(
    lambda x: graph.invoke({"input": x}),
    data=dataset,
    evaluators=[exact_match_evaluator],
    experiment_prefix="v1"
)
```

---

## ðŸŽ¯ Casos de Uso ComÃºn

### 1. Entender Latencia

**Pregunta:** "Â¿Por quÃ© la respuesta tarda 5 segundos?"

**En LangSmith:**
1. Abre la traza
2. Cada nodo muestra su tiempo
3. El nodo mÃ¡s lento es el cuello de botella

**Ejemplo de Output:**
```
Sales Agent: 2.3s
â”œâ”€ ChromaDB Search: 1.8s â† Â¡AQUÃ estÃ¡ el problema!
â”œâ”€ OpenAI Call: 0.4s
â””â”€ Response Formatting: 0.1s
```

### 2. Optimizar Prompts

**Problema:** "Las respuestas no son lo suficientemente buenas"

**Con LangSmith:**
1. Abre la traza del "OpenAI Call"
2. Haz clic en "Edit Prompt"
3. Modifica el prompt directamente
4. Prueba sin redeploy (feature: "Playground")
5. Si es mejor, copia el nuevo prompt
6. Actualiza en `sales_agent_v3.py`

### 3. Monitorear Costos

**Dashboard â†’ Monitoring:**
- Total tokens gastados
- Costo en USD
- Desglose por modelo
- Tasa de errores

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Proyectos Separados por Entorno

```env
# .env.development
LANGCHAIN_PROJECT=utec-sales-agent-dev

# .env.production
LANGCHAIN_PROJECT=utec-sales-agent-prod
```

### Filtrar Trazas

En LangSmith, filtra por:
- **User ID** - Rastrear usuario especÃ­fico
- **Status** - Error vs Success
- **Latency** - Tiempo de respuesta
- **Token Count** - Uso de API

### Custom Tags

```python
# En tu cÃ³digo (avanzado)
from langchain_core.callbacks import tags_callbacks

with tags_callbacks({"user_id": "user_123", "feature": "chat"}):
    response = await graph.ainvoke(input_data)

# En LangSmith, verÃ¡s estos tags y podrÃ¡s filtrar
```

---

## ðŸš¨ SoluciÃ³n de Problemas

### Las trazas no aparecen

**Checklist:**
1. `LANGCHAIN_TRACING_V2=true` âœ“
2. `LANGCHAIN_API_KEY` no estÃ¡ vacÃ­o âœ“
3. API reiniciada despuÃ©s de cambios `.env` âœ“
4. Red permite conexiones a `https://api.smith.langchain.com` âœ“

**Debug:**
```python
# En Python shell
import os
print(os.getenv("LANGCHAIN_TRACING_V2"))
print(os.getenv("LANGCHAIN_API_KEY")[:10] + "...")
```

### Errores de Rate Limit

"Too many requests" â†’ Plan gratuito de LangSmith tiene lÃ­mites

**Soluciones:**
1. Aumentar delay entre requests
2. Upgrade a plan pagado
3. Reducir frecuencia de ejecuciones

### Datos sensibles en Trazas

**Problemas:** Los prompts/respuestas se ven en LangSmith

**Soluciones:**
1. Configurar masking en LangSmith (Settings â†’ Data)
2. Usar `LANGCHAIN_ENDPOINT` privado
3. No incluir datos sensibles en prompts

---

## ðŸ’¡ Best Practices

### 1. Nombres Descriptivos
```env
# âŒ Evitar
LANGCHAIN_PROJECT=test

# âœ… Recomendado
LANGCHAIN_PROJECT=utec-sales-agent-v3-openai
```

### 2. Tags Ãštiles
```python
# Agregar contexto a cada ejecuciÃ³n
tags = {
    "model": "gpt-4o-mini",
    "feature": "chat",
    "user_type": "anonymous",
    "language": "es"
}
```

### 3. Monitorear Regularmente
- Revisa mÃ©tricas semanalmente
- Alertas de errores
- Tendencias de latencia

---

## ðŸ“š Recursos

- **LangSmith Docs**: https://docs.smith.langchain.com/
- **LangChain Observability**: https://docs.langchain.com/docs/langsmith/
- **Video Tutorial**: https://www.youtube.com/watch?v=...

---

## ðŸ” Seguridad

### No Compartir API Keys
```bash
# âŒ Nunca hagas esto
git add .env.local  # â† contiene LANGCHAIN_API_KEY

# âœ… Correcto
echo ".env.local" >> .gitignore
git add .gitignore
```

### RotaciÃ³n de Keys
```
LangSmith Dashboard â†’ Settings â†’ API Keys
â†’ Revoke old key
â†’ Crear nueva key
â†’ Actualizar en tu cÃ³digo
```

---

**Ãšltima actualizaciÃ³n**: 2025-01-08
**Compatible con**: LangSmith 0.2.0+
